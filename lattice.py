# -*- coding: utf-8 -*-
"""lattice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TfYN6kTky2o_98AFUpm6ysHn28rj8KcP

#"LATTİCE PARAMETER OPTİMİZATİON"
**WITH MULTIPLE REGRESSION**

##Import to Librarys
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor
from sklearn import tree
#% matplotlib inline

"""
##Download Data (format CSV)"""

dt = pd.read_csv('/content/dataset_lattice_50.csv')
dt.head()

dt = dt.sample(frac=1, random_state=42).reset_index(drop=True)

dt.head()

dt.info()

"""## Checking the Number of Null Values in the Dataset"""

dt.isnull().sum()

dt.describe()

"""##Correlation Diamgram"""

from matplotlib.cm import scale
corr = dt.corr()
sns.heatmap(corr, annot = True)

"""


##Data Visualization



"""

sns.set(style='white',font_scale=1.2, rc={'figure.figsize':(10,10)})
ax=dt.hist(bins=20,color='red' )

"""#Correlations Scatter Plot """

#sns.pairplot(dt, height=3)

dt2=dt.drop('force',axis=1)
dt2.plot(kind='box', vert=False, figsize=(10, 10))
plt.show()

#Q1 = dt.quantile(0.25)
#Q3 = dt.quantile(0.75)
#IQR = Q3 - Q1

#alt_sinir = Q1 - 1.5*IQR
#ust_sinir = Q3 + 1.5*IQR

#dt = dt[(dt >= alt_sinir) & (dt <= ust_sinir)]

dt2.plot(kind='box', vert=False, figsize=(10, 10))
plt.show()

#dt.isnull().sum()

#from sklearn.impute import KNNImputer

#imputer = KNNImputer(n_neighbors=3)
#dt1= imputer.fit_transform(dt)

#dt = pd.DataFrame(dt1, columns=dt.columns)

"""# Sample Replication with "Boostrap Method"
"""

#bootstrap_sample = dt.sample(n=1000, replace=True)
#dt = pd.concat([dt, bootstrap_sample])

#dt

"""##Correlation Diagram After Boostrap"""

#from matplotlib.cm import scale
#corr = dt.corr()
#sns.heatmap(corr, annot = True)

"""#Target Feature Separation"""

X = dt.drop(['target lenght',	'min diameter',	'max diameter'], axis = 1)
y1=dt['target lenght']
y2=dt['min diameter']
y3=dt['max diameter']

X

"""# Feature Shape Control"""

y1.shape,X.shape

y2.shape,X.shape

y3.shape,X.shape

"""#Feature Visualization

First 5 lines for feature 'Stress' and 'max diameter'
"""

X.head()

from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

"""#Split

Train Test Split for 'Stress'
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42,)
X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42,)
X_train, X_test, y3_train, y3_test = train_test_split(X, y3, test_size=0.2, random_state=42,)

X_train, X_val, y1_train, y1_val, y2_train, y2_val, y3_train, y3_val = train_test_split(X_train, y1_train, y2_train, y3_train, test_size=0.2, random_state=42)

# Her bir setin boyutları kontrol edilir
print("Train 1 set boyutu: ", X_train.shape, y1_train.shape)
print("Validation 1 set boyutu: ", X_val.shape, y1_val.shape)
print("Test 1 set boyutu: ", X_test.shape, y1_test.shape)

print("Train 2 set boyutu: ", X_train.shape, y2_train.shape)
print("Validation 2 set boyutu: ", X_val.shape, y2_val.shape)
print("Test 2 set boyutu: ", X_test.shape, y2_test.shape)

print("Train 3 set boyutu: ", X_train.shape, y3_train.shape)
print("Validation 3 set boyutu: ", X_val.shape, y3_val.shape)
print("Test 3 set boyutu: ", X_test.shape, y3_test.shape)

"""#Normalization Scaler"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train.shape

"""##Multioutput Regressor for Using Boostrap and RandomForest"""

model = RandomForestRegressor(n_estimators = 400, random_state =0)

# BaggingRegressor kullanarak MultiOutputRegressor modeli tanımlama
bagging_model = BaggingRegressor(base_estimator=model, n_estimators=10, random_state=0)

# MultiOutputRegressor kullanarak bootstrap yöntemini uygulama
bootstrap_model = MultiOutputRegressor(bagging_model)

# Eğitim verilerini kullanarak modeli eğitme
bootstrap_model.fit(X_train, np.column_stack((y1_train, y2_train,y3_train)))

"""##Predictiving to Target Features for RF"""

y_test_pred = bootstrap_model.predict(X_test)

y_val_pred= bootstrap_model.predict(X_val)

y1_test_pred, y2_test_pred,y3_test_pred = y_test_pred[:, 0], y_test_pred[:, 1],y_test_pred[:,2]

y1_val_pred, y2_val_pred,y3_val_pred = y_val_pred[:, 0], y_val_pred[:, 1],y_val_pred[:,2]

"""##Mean Square Error (MSE)"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

mse_y1_test = mean_squared_error(y1_test,y1_test_pred)
mse_y2_test = mean_squared_error(y2_test, y2_test_pred)
mse_y3_test = mean_squared_error(y3_test, y3_test_pred)

print(f"Y1 için MSE: {mse_y1_test:.2f}")
print(f"Y2 için MSE: {mse_y2_test:.2f}")
print(f"Y3 için MSE: {mse_y3_test:.2f}")

mse_y1_val = mean_squared_error(y1_val,y1_val_pred)
mse_y2_val = mean_squared_error(y2_val, y2_val_pred)
mse_y3_val = mean_squared_error(y3_val, y3_val_pred)
print(f"Y1 için MSE: {mse_y1_val:.2f}")
print(f"Y2 için MSE: {mse_y2_val:.2f}")
print(f"Y3 için MSE: {mse_y3_val:.2f}")

"""## R-Square Error (R²)"""

r2_y1 = r2_score(y1_test, y1_test_pred)
r2_y2 = r2_score(y2_test, y2_test_pred)
r2_y3 = r2_score(y3_test, y3_test_pred)
print(f"Y1 için R-kare: {r2_y1:.2f}")
print(f"Y2 için R-kare: {r2_y2:.2f}")
print(f"Y3 için R-kare: {r2_y3:.2f}")

r2_y1 = r2_score(y1_val, y1_val_pred)
r2_y2 = r2_score(y2_val, y2_val_pred)
r2_y3 = r2_score(y3_val, y3_val_pred)
print(f"Y1 için R-kare: {r2_y1:.2f}")
print(f"Y2 için R-kare: {r2_y2:.2f}")
print(f"Y3 için R-kare: {r2_y3:.2f}")

"""
# MultiOutput Regressor for Using Gradient Boosting Regressor

"""

from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression as lr

from sklearn.ensemble import GradientBoostingRegressor
mor = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=0.1)

#rf = RandomForestRegressor(n_estimators = 400, random_state =0)
#mor = MultiOutputRegressor(rf)

from sklearn.ensemble import GradientBoostingRegressor

params = {'n_estimators': 500,
          'max_depth': 5,
          'min_samples_split': 6,
          'learning_rate': 0.005,
          'loss': 'absolute_error'}

# Modeli oluşturma
gb_model = GradientBoostingRegressor(**params)



# Modeli eğitme

mor = MultiOutputRegressor(gb_model)
mor.fit(X_train, np.column_stack((y1_train, y2_train,y3_train)))

"""##Predictiving to Target Features GB"""

y_test_pred = mor.predict(X_test)

y_val_pred= mor.predict(X_val)

y1_test_pred, y2_test_pred,y3_test_pred = y_test_pred[:, 0], y_test_pred[:, 1],y_test_pred[:,2]

y1_val_pred, y2_val_pred,y3_val_pred = y_val_pred[:, 0], y_val_pred[:, 1],y_val_pred[:,2]

"""##Mean Square Error (MSE)"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

mse_y1_test = mean_squared_error(y1_test,y1_test_pred)
mse_y2_test = mean_squared_error(y2_test, y2_test_pred)
mse_y3_test = mean_squared_error(y3_test, y3_test_pred)

print(f"Y1 için MSE: {mse_y1_test:.2f}")
print(f"Y2 için MSE: {mse_y2_test:.2f}")
print(f"Y3 için MSE: {mse_y3_test:.2f}")

mse_y1_val = mean_squared_error(y1_val,y1_val_pred)
mse_y2_val = mean_squared_error(y2_val, y2_val_pred)
mse_y3_val = mean_squared_error(y3_val, y3_val_pred)
print(f"Y1 için MSE: {mse_y1_val:.2f}")
print(f"Y2 için MSE: {mse_y2_val:.2f}")
print(f"Y3 için MSE: {mse_y3_val:.2f}")

"""## R-Square Error (R²)"""

r2_y1 = r2_score(y1_test, y1_test_pred)
r2_y2 = r2_score(y2_test, y2_test_pred)
r2_y3 = r2_score(y3_test, y3_test_pred)
print(f"Y1 için R-kare: {r2_y1:.2f}")
print(f"Y2 için R-kare: {r2_y2:.2f}")
print(f"Y3 için R-kare: {r2_y3:.2f}")

r2_y1 = r2_score(y1_val, y1_val_pred)
r2_y2 = r2_score(y2_val, y2_val_pred)
r2_y3 = r2_score(y3_val, y3_val_pred)
print(f"Y1 için R-kare: {r2_y1:.2f}")
print(f"Y2 için R-kare: {r2_y2:.2f}")
print(f"Y3 için R-kare: {r2_y3:.2f}")

"""##Improvement with Hyperparameter Tuning"""

from sklearn.ensemble import GradientBoostingRegressor

# Gradient Boosting Regressor modeli için ayarlar
params = {'n_estimators': 500,
          'max_depth': 5,
          'min_samples_split': 6,
          'learning_rate': 0.009,
          'loss': 'squared_error'}

# Modeli oluşturma
gb_model1 = GradientBoostingRegressor(**params)

# Modeli eğitme
gb_model1.fit(X_train, y1_train)

y1_pred = gb_model1.predict(X_test)

# Model performansını değerlendire
mse = mean_squared_error(y1_test, y1_pred)
r2 = gb_model1.score(X_test, y1_test)

print("MSE: {:.2f}".format(mse))
print("R^2 score: {:.2f}".format(r2))

from sklearn.ensemble import GradientBoostingRegressor

# Gradient Boosting Regressor modeli için ayarlar
params = {'n_estimators': 1000,
          'max_depth': 5,
          'min_samples_split': 7,
          'learning_rate': 0.01,
          'loss': 'huber'}

# Modeli oluşturma
gb_model2 = GradientBoostingRegressor(**params)

# Modeli eğitme
gb_model2.fit(X_train, y2_train)

y2_pred = gb_model2.predict(X_test)

# Model performansını değerlendire
mse = mean_squared_error(y2_test, y2_pred)
r2 = gb_model2.score(X_test, y2_test)

print("MSE: {:.2f}".format(mse))
print("R^2 score: {:.2f}".format(r2))

from sklearn.ensemble import GradientBoostingRegressor

# Gradient Boosting Regressor modeli için ayarlar
params = {'n_estimators': 500,
          'max_depth': 5,
          'min_samples_split': 6,
          'learning_rate': 0.05,
          'loss': 'absolute_error'}

# Modeli oluşturma
gb_model3 = GradientBoostingRegressor(**params)

# Modeli eğitme
gb_model3.fit(X_train, y3_train)

y1_pred = gb_model3.predict(X_test)

# Model performansını değerlendire
mse = mean_squared_error(y3_test, y3_test_pred)
r2 = gb_model3.score(X_test, y3_test)

print("MSE: {:.2f}".format(mse))
print("R^2 score: {:.2f}".format(r2))



"""##An Example of Using the Model"""

selected_row = dt.loc[35,:]
print(selected_row)

target_lenght =gb_model1.predict(np.array([[12.1,17.83,0.009,100,0.5071,4000]]))
target_lenght

oran=gb_model2.predict(np.array([[363.3,67.8,72.7,1143,659,155,7.56,3.4]]))

uzunluk=gb_model3.predict(np.array([[363.3,67.8,72.7,1143,659,155,7.56,3.4]]))

print(f"Tahmin edilen değerler=\ntarget lenght={cap}\nmax diameter(mm)={uzunluk}\nmin diameter(mm)={oran} \n\nGerçek değerler=\n{dt.iloc[250,7:10]}")